####  Using neural network for create regression model CLIs-CRNs
  + 
```{r init}
rm(list=ls())
assign("last.warning", NULL, envir = baseenv())
source("http://tmeits.github.io/24516/transect/setdw.R")
wd <- "C:/Users/IVA/Dropbox/24516/nnet_transect/nnet_24643"
setwd(wd)
```
#### Reading generalized chronologies from the site https://www.ncdc.noaa.gov/paleo/chron_table.html
  + <https://www.ncdc.noaa.gov/paleo/meas_table.html>
  + <ftp://ftp.ncdc.noaa.gov/pub/data/paleo/treering/updates/schweingruber/chronologies/russ055/russ055w_tabs.crn>
  + <ftp://ftp.ncdc.noaa.gov/pub/data/paleo/treering/updates/schweingruber/chronologies/russ055/russ055w_out.txt>
  + <https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf>
```{r read_rwi_data}
library(reshape2)
library(data.table)
# http://meteo.ru/data/155-meteostations
# 63.23, 125.48   63.95, 124.83  https://yandex.ru/maps/-/CZwvQZpz
DTw <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/paleo/treering/updates/schweingruber/chronologies/russ055/russ055w_tabs.crn")
DTe <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/paleo/treering/updates/schweingruber/chronologies/russ055/russ055e_tabs.crn")
str(DTw)
head(DTw)
DTw[YEAR %in% c(1:5000)]
length(c(min(DTw[,YEAR]): max(DTw[,YEAR]))) == length(DTw[,YEAR])
DTw[, .(YEAR,STD)]
DTw[, plot(YEAR,RES,type="l", col="red")]
DTw[, lines(YEAR,ARS,type="l", col="blue")]
DTw[, lines(YEAR,STD,type="l", col="green")]

```
#### Read climate station data 24643 (Temperature, precipitation, illumination)
```{r set_24643}


```
#### To make the same start and end year input and output data
```{r make_same}
make_same <- function(train_in, train_out) {
    min_in <- min(train_in$Year)
    min_out <- min(train_out$year)
    max_in <- max(train_in$Year)
    max_out <- max(train_out$year)
    start_year <- max(min_in, min_out)
    end_year <- min(max_in, max_out)
    return(c(start_year, end_year))
}
train_in <- MT[MT$Station == 24643, ]
train_out <- russ055.rwi
make_same(train_in, train_out)
```
####  restoration of the elapsed years by copying the previous year
#### create a training training set
```{r data_train}
restoration_elapsed_years <- function(long_vector, short_vector) {

    return(long_vector[-c(long_vector[-c(short_vector)])])

}
y1 <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
y2 <- c(1, 2, 4, 5, 6, 8, 9)
restoration_elapsed_years(y1, y2)

#[1] 1 2 4 5 6 8 9

data_train <- function(train_in, train_out, start_year, end_year) {
   tr_in <-  train_in[train_in$Year >= start_year & train_in$Year <= end_year, ]
   tr_out  <- train_out[train_out$year >= start_year & train_out$year <= end_year, ]
   print(summary(tr_in))
   print(summary(tr_out))
   print(str(tr_in))
   print(str(tr_out))
   #trainingdata <- cbind(tr_in, CRN = as.vector(tr_out[, 2]))
   return(list(tr_in, tr_out))
}
se_year <-  make_same(MT[MT$Station == 24643, ], russ055.rwi)
print(se_year)
train <- data_train(MT[MT$Station == 24643, ], russ055.rwi, se_year[1], se_year[2])
str(train)
train_in <- train[[1]]
train_out <- train[[2]]
train_out2 <- train_out[-c(4, 6, 10, 22), ]
# Разная длина в годах. начало и конец одинаковые. Задача сравнять длину.
save(train_in, train_out, train_out2, file=paste0(nnet_path, "/train_in_out.24643.Rdata"))
load(file=paste0(nnet_path, "/train_in_out.24643.Rdata"))

```
#### Compare the annual growth rings on the stations and years with climate data
```{r neuralnet_crn}
install.packages('neuralnet', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(neuralnet)
library(NeuralNetTools)
set.seed(1410) # Make the sample reproducible

str(train_in)
summary(train_in)
plot(train_in)
qplot(train_in)
# https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf
require(ggplot2)
qplot(1:12, sapply(train_in[3:14], mean), geom = c("point", "smooth"))
plot(1:12, sapply(train_in[3:14], mean), geom = c("point", "smooth"))

# http://dendrobox.org/

train.sample <- data.frame(train_in, CRN=train_out2[,2]) [, 3:15]
#
t2<-rbind(train.sample,train.sample)
train.sample <- rbind(t2,t2)
train.sample <-rbind(train.sample, train.sample)
# Train the neural network
print(net.crn <- neuralnet(CRN ~ Cli_m1 + Cli_m2 + Cli_m3 + Cli_m4 + Cli_m5 + 
    Cli_m6 + Cli_m7 + Cli_m8 + Cli_m9 + Cli_m10 + Cli_m11 + Cli_m12, train.sample, 
    hidden = c(13,7), rep = 1, linear.output = TRUE, threshold = 0.02, stepmax = 100000))

testdata <- train.sample[, 1:12]
net.results <- compute(net.crn, testdata) #Run them through the neural network
ls(net.results)
#Lets see the results
print(net.results$net.result)

plot(train_out2[,1], net.results$net.result, axes=TRUE,col='blue', lwd=3,
  main="Computes the outputs covariate vectors given a trained neural network.",
  xlab="Years", ylab="RWI")
lines(train_out2[,1], net.results$net.result, col='blue', lwd=3)
points(train_out2[,1], train.sample[, 13], col='red', lwd=2)
lines(train_out2[,1], train.sample[, 13], col='red', lwd=2)
legend("topleft", c("Real","Eval"), col = c("blue", "red"), lwd = c(3,2), title="Chronology")
grid(10,10)

# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/compute?
# http://blog.revolutionanalytics.com/2015/08/plotting-time-series-in-r.html
# http://www.idlcoyote.com/cg_tips/al_legend_1.png
# http://www.sthda.com/english/wiki/ggplot2-line-types-how-to-change-line-types-of-a-graph-in-r-software
library(ggplot2)
df2 <- data.frame(Chronology = rep(c("Eval", "Real"), each=3),
                  time=c("breakfeast", "Lunch", "Dinner"),
                  bill=c(10, 30, 15, 13, 40, 17) )
df2 <- data.frame(Chronology = c(rep(c("training_sample"), each=length(train_out2[,1])), rep(c("testing_sample"), each=length(train_out2[,1]))),
                   year=as.character(c(train_out2[,1],train_out2[,1])),
                   rwi=c(train.sample[, 13], net.results$net.result))                  
head(df2)
# Change line types + colors
ggplot(df2, aes(x=year, y=rwi, group=Chronology)) +
  geom_line(aes(linetype=Chronology, color=Chronology), size=1.1)+
  geom_point(aes(color=Chronology), size=3)+
  theme(legend.position="top")






#ggplot2 http://r-statistics.co/ggplot2-Tutorial-With-R.html
# Approach 1:
data(economics, package="ggplot2")  # init data
economics <- data.frame(economics)  # convert to dataframe
ggplot(economics) + geom_line(aes(x=date, y=pce, color="pcs")) + geom_line(aes(x=date, y=unemploy, col="unemploy")) + scale_color_discrete(name="Legend") + labs(title="Economics") # plot multiple time series using 'geom_line's

# https://learnr.wordpress.com/2009/05/05/ggplot2-two-time-series-with-different-dates/
df <- structure(list(date = structure(c(4L,
     10L, 16L, 19L, 2L, 14L, 20L, 6L, 12L, 4L,
     5L, 10L, 11L, 13L, 15L, 16L, 17L, 18L,
     1L, 2L, 3L, 7L, 8L, 9L, 14L, 20L), .Label = c("01-Dec-08",
     "02-Dec-08", "04-Dec-08", "04-Nov-08",
     "05-Nov-08", "06-Jan-09", "08-Dec-08",
     "10-Dec-08", "11-Dec-08", "11-Nov-08",
     "12-Nov-08", "13-Jan-09", "13-Nov-08",
     "16-Dec-08", "17-Nov-08", "18-Nov-08",
     "20-Nov-08", "24-Nov-08", "25-Nov-08",
     "30-Dec-08"), class = "factor"), value = c(5.9,
     6, 6.1, 6.2, 6.1, 5.8, 6.1, 5.5, 5.9, 5.7,
     6.2, 6.1, 5.7, 6, 6, 6.2, 6.2, 6.1, 6,
     5.7, 6.1, 5.9, 5.7, 6, 5.9, 6.1), variable = structure(c(1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"),
     class = "factor")), .Names = c("date",
     "value", "variable"), class = "data.frame",
     row.names = c(NA, -26L))
df$date <- as.Date(df$date, format = "%d-%b-%y")
ggplot(df, aes(x = date, y = value, group = variable, colour = variable)) + geom_point() + geom_line()
# http://www.bioconductor.org/help/workflows/rnaseqGene/     


knitr::kable(round(train.sample,2), format = "markdown")
save(net.crn, file=paste0(nnet_path, "/net20112016.Rdata"))
# Save the neural network
save(net.crn, traininginput, trainingoutput, trainingdata, trainingdata.sample, file=paste0(nnet_path, "/net.Rdata"))
load(file=paste0(nnet_path, "/net.Rdata"))
# Plot the neural network
plot(net.crn, rep="best")
plotnet(net.crn, alpha=0.6)
#prediction(net.crn)
gwplot(net.crn, selected.covariate="Cli_m5")
gwplot(net.crn)
```
#### 

  + <https://rdrr.io/cran/neuralnet/> 
```{r neuralnet}
library(neuralnet)
library(NeuralNetTools)

# Make up some new data
n <- 65
mint <- -40
maxt <-40
traininginput <- data.frame(m1 = runif(n, mint, maxt), m2 = runif(n, mint, maxt), 
    m3 = runif(n, mint, maxt), m4 = runif(n, mint, maxt), m5 = runif(n, 
        mint, maxt), m6 = runif(n, mint, maxt), m7 = runif(n, mint, maxt), 
    m8 = runif(n, mint, maxt), m9 = runif(n, mint, maxt), m10 = runif(n, 
        mint, maxt), m11 = runif(n, mint, maxt), m12 = runif(n, mint, 
        maxt))
traininginput<-round(traininginput,2)
trainingoutput<-apply(traininginput, 1, function(x) sqrt(abs(sum(x))))
trainingoutput<-as.vector(trainingoutput)  # CRN

 
#Column bind the data into one variable
trainingdata <- cbind(traininginput, CRN=trainingoutput)
#colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Going to have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.crn <- neuralnet(CRN~m1+m2+m3+m4+m5+m6+m7+m8+m9+m10+m11+m12,trainingdata, hidden=c(15), rep = 1, linear.output = TRUE, threshold=0.01)



print(net.crn)
#par(mar = numeric(4), family = 'serif')
plotnet(net.crn, alpha=0.6) 
#Plot the neural network
plot(net.crn)
 
#Test the neural network on some training data
testdata <- as.data.frame(trainingoutput[12:45]) 
testdata <-traininginput[10:25,]
net.results <- compute(net.crn, testdata) #Run them through the neural network
 
#Lets see what properties net.sqrt has
ls(net.results)
 
#Lets see the results
print(net.results$net.result)
 
#Lets display a better version of the results
cleanoutput <- cbind(testdata, trainingoutput[10:25], as.data.frame(net.results$net.result))
#colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)

plot(trainingoutput[10:25], net.results$net.result)

plot(BostonHousing$medv, nnet.predict, main="Neural network predictions vs actual", xlab="Actual")

```
```{r plot_net}
library(neuralnet)
 
#response
CRN<-c(rep(0,7),1)
OR<-c(0,rep(1,7))
 
#response with predictors
binary.data<-data.frame(expand.grid(c(0,1),c(0,1),c(0,1)),CRN,OR)
colnames(binary.data) <- c("Temp","Prec","Soil","CRN","OR")
 
#model
net<-neuralnet(CRN~Temp+Prec+Soil, binary.data,hidden=c(6,12,8),rep=10,err.fct="ce",linear.output=FALSE)
 
#plot ouput
par(mar=numeric(4),family='serif')
plotnet(net)

```
```{r tips}

http://www.habrahabr.net/thread/4406
http://r-analytics.blogspot.ru/2012/11/shiny-r.html#.WDGSy8WalKg
http://biostat-r.blogspot.ru/2016/01/tidy-data.html#more  !!!!!
http://belousovv.ru/markdown_syntax
http://cyberleninka.ru/article/n/postroenie-bystryh-approksimatsionnyh-moduley-resheniya-zadach-vysokochastotnogo-elektromagnitnogo-karotazha
http://sil.uc.edu/pdfFiles/pawel/PN_ITM2012_WRF_Ozone.pdf
http://pca.narod.ru/lecture4.htm
https://geektimes.ru/post/211610/
http://swblog.ru/articles/other/postroenie-nejronnoj-seti.html
https://geographyofrussia.com/set-meteostancij/
http://aakinshin.net/ru/about/
https://rstudio-pubs-static.s3.amazonaws.com/65323_76ad54e90cd845eab4b7569c81c9d5b0.html
https://cran.r-project.org/web/views/ReproducibleResearch.html
http://ru.stackoverflow.com/questions/467172/%D0%9A%D0%B0%D0%BA-%D0%BF%D0%B5%D1%80%D0%B5%D0%BD%D0%B5%D1%81%D1%82%D0%B8-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%83-%D0%B2-%D1%83%D0%B4%D0%BE%D0%B1%D0%BD%D1%8B%D0%B9-%D0%B4%D0%BB%D1%8F-%D0%BF%D1%83%D0%B1%D0%BB%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8-%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82
https://www.ncdc.noaa.gov/paleo/treeinfo.html

require(tcltk)
total <- 20
# create progress bar
pb <- tkProgressBar(title = "progress bar", min = 0,
                    max = total, width = 300)

for(i in 1:total){
   Sys.sleep(1)
   setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
                                        "% done"))
}
close(pb)
# create progress bar
pb <- winProgressBar(title = "progress bar", min = 0,
                     max = total, width = 300)

for(i in 1:total){
   Sys.sleep(0.1)
   setWinProgressBar(pb, i, title=paste( round(i/total*100, 0),
                                        "% done"))
}
close(pb)

# https://bookdown.org/statist_/DataTableManual/01_data.table_intro.html#ch1.1
# http://www.brodrigues.co/fput/unit-testing.html#introduction
# https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf
library(reshape2)
library(data.table)

set.seed(45L)

DT <- data.table(V1=c(1L,2L),  V2=LETTERS[1:3], V3=round(rnorm(4),4), V4=1:12)
set.seed(45L)
DF <- data.frame(V1=c(1L,2L),  V2=LETTERS[1:3], V3=round(rnorm(4),4), V4=1:12)
DF
DT = fread("https://raw.githubusercontent.com/wiki/Rdatatable/data.table/data/melt_default.csv")

https://habrahabr.ru/company/infopulse/blog/301914/
https://statist.shinyapps.io/bioeq/
# http://web.utk.edu/~grissino/software.htm#dendrometer
# https://toster.ru/q/79828
# http://matlab.exponenta.ru/neuralnetwork/book1/task1/task1.php
# https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/
# https://heuristically.wordpress.com/2011/11/17/using-neural-network-for-regression/
# https://www.r-bloggers.com/general-regression-neural-network-with-r/
# http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/
# https://rpubs.com/mbaumer/NeuralNetworks
# https://beckmw.wordpress.com/2014/12/20/neuralnettools-1-0-0-now-on-cran/
# https://bzstat.wordpress.com/2011/07/10/using-lib-fann-in-r-via-rcpp/
# install.packages('NeuralNetTools', dependencies=TRUE, repos='http://cran.rstudio.com/')
# install.packages('neuralnet', dependencies=TRUE, repos='http://cran.rstudio.com/')
# install.packages('txtplot', dependencies=TRUE, repos='http://cran.rstudio.com/')
# install.packages('tcltk', dependencies=TRUE, repos='http://cran.rstudio.com/')

# http://www.theanalysisfactor.com/r-programming-plotting-color-part-2-qplot/
```
#### Atom 
```{r atom}
D410PTL
DG945GCLF
http://cdimage.ubuntu.com/ubuntu-mate/releases/16.04.1/release/ubuntu-mate-16.04.1-desktop-i386.iso
http://ark.intel.com/ru/products/48480/Intel-Desktop-Board-D410PTL
http://www.nix.ru/autocatalog/motherboards_intel/INTEL-D410PTL-OEM-Atom-D410-NM10-SVGA-plus-LAN-SATA-Mini-ITX-2DDR2-PC2-5300_97721.html
http://ark.intel.com/products/69042/Intel-Desktop-Board-D2550MUD2
KVR1333D3S8S9/2G
PC3-10600 CL9 204 
http://www.intel.com/content/dam/support/us/en/documents/motherboards/desktop/d525mw/d525mw_d525mwv_techprodspec03.pdf

```
